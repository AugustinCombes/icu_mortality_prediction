{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from dataloader import EHRDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models.transformer_model import TransformerPredictor\n",
    "from utils import create_tokenizer, compute_metrics\n",
    "from tqdm import trange, tqdm\n",
    "import copy\n",
    "\n",
    "create_tokenizer()\n",
    "train_dataset = EHRDataset(mode=\"train\")\n",
    "test_dataset = EHRDataset(mode=\"test\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "targets = np.array(list(train_dataset.targets.values()))\n",
    "labels_uniques, counts = np.unique(targets, return_counts=True)\n",
    "class_weights = [sum(counts)/c for c in counts]\n",
    "weights = [class_weights[x] for x in targets]\n",
    "sampler = WeightedRandomSampler(weights, len(targets))\n",
    "\n",
    "criterion = nn.BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_embed, d_transformer = 48, 128\n",
    "\n",
    "model = TransformerPredictor(d_embedding=d_embed, d_model=d_transformer, n_layers=2, tokenizer_codes=train_dataset.tokenizer, dropout=0.5, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1\n",
    "    # weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "best_test_auprc = 0.\n",
    "patience, current_patience = 15, 0\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "start_lr, end_lr = 1e-4, 1e-5\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: start_lr*(1-epoch/epochs) + end_lr*(epoch/epochs))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_prob, y_true = [], []\n",
    "    for e in DataLoader(dataset=train_dataset, batch_size=8, drop_last=False, sampler=sampler):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        minutes, codes, values = e['minutes'].to(device), e['codes'].to(device), e['values'].to(device)\n",
    "        y = e['target'].to(device)\n",
    "\n",
    "        output = model(codes, values, minutes)\n",
    "        loss = criterion(output.squeeze(), y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_prob += output.squeeze().detach().tolist()\n",
    "        y_true += y.tolist()\n",
    "        \n",
    "    acc, auprc, auroc, bce = compute_metrics(y_true, y_prob)\n",
    "    print(f\"Epoch {1+epoch}: train: acc {round(acc, 3)}; auprc {round(auprc, 3)}; auroc {round(auroc, 3)}; bce {round(bce, 3)}\")\n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_prob, y_true = [], []\n",
    "    for e in DataLoader(dataset=test_dataset, batch_size=256, shuffle=False, drop_last=False):\n",
    "        minutes, codes, values = e['minutes'].to(device), e['codes'].to(device), e['values'].to(device)\n",
    "        y = e['target'].to(device)\n",
    "\n",
    "        output = model(codes, values, minutes)\n",
    "        loss = criterion(output.squeeze(), y.float())\n",
    "        \n",
    "        y_prob += output.squeeze().detach().tolist()\n",
    "        y_true += y.tolist()\n",
    "\n",
    "    acc, auprc, auroc, bce = compute_metrics(y_true, y_prob)\n",
    "    print(f\" test: acc {round(acc, 3)}; auprc {round(auprc, 3)}; auroc {round(auroc, 3)}; bce {round(bce, 3)}\\n\")\n",
    "    if auprc > best_test_auprc:\n",
    "        current_patience = 0\n",
    "        best_test_auprc = auprc\n",
    "        best_dict = copy.deepcopy(model.state_dict())\n",
    "        best_row = f\" best test (epoch {epoch}): acc {round(acc, 3)}; auprc {round(auprc, 3)}; auroc {round(auroc, 3)}; bce {round(bce, 3)}\"\n",
    "    else :\n",
    "        current_patience += 1\n",
    "\n",
    "    tqdm.write(best_row)\n",
    "    \n",
    "    if current_patience == patience:\n",
    "        break\n",
    "        \n",
    "\n",
    "torch.save(best_dict, f\"{round(100*best_test_auprc)}%_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(y_true, y_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de1bb33c3a5ec0cd6329752bd7fd6f0ffd7a30d195882c0074119f931c591894"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
